{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation: Normalization/Standardization/Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, KBinsDiscretizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryClassification = pd.read_csv('data/training.csv', sep = ';')\n",
    "\n",
    "X_train = salaryClassification.drop(' salary-classification', 1)\n",
    "y_train =  salaryClassification[' salary-classification']\n",
    "\n",
    "#treat missing values\n",
    "salaryClassification = salaryClassification.replace(' ?', np.NaN)\n",
    "salaryClassification[' workclass'] = salaryClassification[' workclass'].replace(np.NaN, 'Unknown')\n",
    "salaryClassification[' occupation'] = salaryClassification[' occupation'].replace(np.NaN, 'Other')\n",
    "salaryClassification[' native-country'] = salaryClassification[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"workclass\"] = oe.fit_transform(salaryClassification[[\" workclass\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' workclass', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['fnlwgt'] = salaryClassification[' fnlwgt']\n",
    "salaryClassification = salaryClassification.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"education\"] = oe.fit_transform(salaryClassification[[\" education\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' education', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['education-num'] = salaryClassification[' education-num']\n",
    "salaryClassification = salaryClassification.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"marital-status\"] = oe.fit_transform(salaryClassification[[\" marital-status\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"occupation\"] = oe.fit_transform(salaryClassification[[\" occupation\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"relationship\"] = oe.fit_transform(salaryClassification[[\" relationship\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"race\"] = oe.fit_transform(salaryClassification[[\" race\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"sex\"] = oe.fit_transform(salaryClassification[[\" sex\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "salaryClassification['capital-diff'] = salaryClassification[' capital-gain'] - salaryClassification[' capital-loss']\n",
    "salaryClassification = salaryClassification.drop(' capital-gain', 1)\n",
    "salaryClassification = salaryClassification.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['hours-per-week'] = salaryClassification[' hours-per-week']\n",
    "salaryClassification = salaryClassification.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"native-county\"] = oe.fit_transform(salaryClassification[[\" native-country\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "salaryClassification[' salary-classification'] = [x.replace(' <=50K', '0') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = [x.replace(' >50K', '1') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = salaryClassification[' salary-classification'].astype(int)\n",
    "\n",
    "salaryClassification['salary-classification'] = salaryClassification[' salary-classification']\n",
    "salaryClassification = salaryClassification.drop(' salary-classification',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('data/test.csv', sep = ';')\n",
    "\n",
    "X_test = testData.drop(' salary-classification', 1)\n",
    "y_test =  testData[' salary-classification']\n",
    "\n",
    "#treat missing values\n",
    "testData = testData.replace(' ?', np.NaN)\n",
    "testData[' workclass'] = testData[' workclass'].replace(np.NaN, 'Unknown')\n",
    "testData[' occupation'] = testData[' occupation'].replace(np.NaN, 'Other')\n",
    "testData[' native-country'] = testData[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"workclass\"] = oe.fit_transform(testData[[\" workclass\"]]).astype(int)\n",
    "testData = testData.drop(' workclass', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['fnlwgt'] = testData[' fnlwgt']\n",
    "testData = testData.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"education\"] = oe.fit_transform(testData[[\" education\"]]).astype(int)\n",
    "testData = testData.drop(' education', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['education-num'] = testData[' education-num']\n",
    "testData = testData.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"marital-status\"] = oe.fit_transform(testData[[\" marital-status\"]]).astype(int)\n",
    "testData = testData.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"occupation\"] = oe.fit_transform(testData[[\" occupation\"]]).astype(int)\n",
    "testData = testData.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"relationship\"] = oe.fit_transform(testData[[\" relationship\"]]).astype(int)\n",
    "testData = testData.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"race\"] = oe.fit_transform(testData[[\" race\"]]).astype(int)\n",
    "testData = testData.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"sex\"] = oe.fit_transform(testData[[\" sex\"]]).astype(int)\n",
    "testData = testData.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "testData['capital-diff'] = testData[' capital-gain'] - testData[' capital-loss']\n",
    "testData = testData.drop(' capital-gain', 1)\n",
    "testData = testData.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['hours-per-week'] = testData[' hours-per-week']\n",
    "testData = testData.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"native-county\"] = oe.fit_transform(testData[[\" native-country\"]]).astype(int)\n",
    "testData = testData.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "testData[' salary-classification'] = [x.replace(' <=50K', '0') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = [x.replace(' >50K', '1') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = testData[' salary-classification'].astype(int)\n",
    "\n",
    "testData['salary-classification'] = testData[' salary-classification']\n",
    "testData = testData.drop(' salary-classification',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScaling(train):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(train)\n",
    "    return train;\n",
    "\n",
    "\n",
    "def robustScaling(train):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(train)\n",
    "    return train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(train):\n",
    "    ftd = ['age', 'hours-per-week', 'education-num', 'capital-diff']\n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    train[ftd] = discretizer.fit_transform(train[ftd])\n",
    "    return train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train):\n",
    "    train = transformer = Normalizer().fit_transform(train)\n",
    "    return train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed linear svm. \n",
    "def evaluateTechnique(transformer):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "\n",
    "    X_train = transformer(X_train)\n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        SGDClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(max_iter=10000),\n",
    "\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "\n",
    "    names = [\"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \n",
    "             \n",
    "             \"Gaussian Naive Bayes\",\n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "            \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_validate(clf, X_train, y_train, cv=5, scoring={'accuracy', 'roc_auc'})\n",
    "        print(\"Accuracy: %0.3f (+/- %0.3f) | AUROC %0.3f || \" % (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['test_roc_auc'].mean()), name)\n",
    "        \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790 (+/- 0.017) | AUROC 0.683 ||  Logistic regression\n",
      "Accuracy: 0.786 (+/- 0.007) | AUROC 0.576 ||  SGDClassifier\n",
      "Accuracy: 0.777 (+/- 0.003) | AUROC 0.672 ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.793 (+/- 0.002) | AUROC 0.560 ||  SVM-rbf\n",
      "Accuracy: 0.795 (+/- 0.006) | AUROC 0.833 ||  Gaussian Naive Bayes\n",
      "Accuracy: 0.810 (+/- 0.006) | AUROC 0.745 ||  Decision Tree\n",
      "Accuracy: 0.701 (+/- 0.342) | AUROC 0.658 ||  Multi-layer Perceptron\n",
      "Accuracy: 0.860 (+/- 0.010) | AUROC 0.914 ||  AdaBoost\n",
      "Accuracy: 0.856 (+/- 0.008) | AUROC 0.904 ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(standardScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790 (+/- 0.017) | AUROC 0.683 ||  Logistic regression\n",
      "Accuracy: 0.673 (+/- 0.433) | AUROC 0.572 ||  SGDClassifier\n",
      "Accuracy: 0.777 (+/- 0.003) | AUROC 0.672 ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.793 (+/- 0.002) | AUROC 0.560 ||  SVM-rbf\n",
      "Accuracy: 0.795 (+/- 0.006) | AUROC 0.833 ||  Gaussian Naive Bayes\n",
      "Accuracy: 0.808 (+/- 0.007) | AUROC 0.744 ||  Decision Tree\n",
      "Accuracy: 0.623 (+/- 0.439) | AUROC 0.643 ||  Multi-layer Perceptron\n",
      "Accuracy: 0.860 (+/- 0.010) | AUROC 0.914 ||  AdaBoost\n",
      "Accuracy: 0.856 (+/- 0.007) | AUROC 0.904 ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(robustScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759 (+/- 0.000) | AUROC 0.507 ||  Logistic regression\n",
      "Accuracy: 0.759 (+/- 0.000) | AUROC 0.507 ||  SGDClassifier\n",
      "Accuracy: 0.717 (+/- 0.007) | AUROC 0.560 ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.759 (+/- 0.000) | AUROC 0.491 ||  SVM-rbf\n",
      "Accuracy: 0.759 (+/- 0.000) | AUROC 0.724 ||  Gaussian Naive Bayes\n",
      "Accuracy: 0.772 (+/- 0.008) | AUROC 0.691 ||  Decision Tree\n",
      "Accuracy: 0.759 (+/- 0.001) | AUROC 0.544 ||  Multi-layer Perceptron\n",
      "Accuracy: 0.834 (+/- 0.013) | AUROC 0.883 ||  AdaBoost\n",
      "Accuracy: 0.806 (+/- 0.002) | AUROC 0.843 ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.777 (+/- 0.001) | AUROC 0.625 ||  Logistic regression\n",
      "Accuracy: 0.776 (+/- 0.001) | AUROC 0.625 ||  SGDClassifier\n",
      "Accuracy: 0.789 (+/- 0.003) | AUROC 0.789 ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.785 (+/- 0.002) | AUROC 0.717 ||  SVM-rbf\n",
      "Accuracy: 0.793 (+/- 0.003) | AUROC 0.773 ||  Gaussian Naive Bayes\n",
      "Accuracy: 0.789 (+/- 0.010) | AUROC 0.718 ||  Decision Tree\n",
      "Accuracy: 0.794 (+/- 0.005) | AUROC 0.735 ||  Multi-layer Perceptron\n",
      "Accuracy: 0.809 (+/- 0.003) | AUROC 0.837 ||  AdaBoost\n",
      "Accuracy: 0.840 (+/- 0.008) | AUROC 0.887 ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação com os conjunto de dados de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScalingTest(train,test): \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(train)\n",
    "    scaled_test = scaler.transform(test)\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def robustScalingTest(train,test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(train)\n",
    "    scaled_test = scaler.transform(test)\n",
    "    return scaled_data, scaled_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretizeTest(train, test):\n",
    "    ftd = ['age', 'hours-per-week', 'education-num', 'capital-diff']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    train[ftd] = discretizer.fit_transform(train[ftd])\n",
    "    test[ftd] = discretizer.transform(test[ftd])\n",
    "    return train, test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeTest(train,test):\n",
    "    normalizer = Normalizer()\n",
    "    train = normalizer.fit_transform(train)\n",
    "    test = normalizer.transform(test)\n",
    "    return train, test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTechniqueTestData(transformer):\n",
    "    \n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test = testData['salary-classification']\n",
    "    \n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        SGDClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(),\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "\n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        evaluateModel(name, y_test, predicted)    \n",
    "    return;  \n",
    "\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"Accuracy: %0.3f | AUROC %0.3f | (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) || \" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819 | AUROC 0.684 | (Accuracy, Precision) 0:( 0.940, 0.842)  1:( 0.428, 0.689) ||  Logistic regression\n",
      "Accuracy: 0.813 | AUROC 0.632 | (Accuracy, Precision) 0:( 0.975, 0.816)  1:( 0.289, 0.779) ||  SGDClassifier\n",
      "Accuracy: 0.826 | AUROC 0.735 | (Accuracy, Precision) 0:( 0.907, 0.870)  1:( 0.563, 0.652) ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.846 | AUROC 0.735 | (Accuracy, Precision) 0:( 0.946, 0.865)  1:( 0.524, 0.749) ||  SVM-rbf\n",
      "Accuracy: 0.825 | AUROC 0.669 | (Accuracy, Precision) 0:( 0.965, 0.833)  1:( 0.373, 0.765) ||  Gaussian naive bayes\n",
      "Accuracy: 0.810 | AUROC 0.740 | (Accuracy, Precision) 0:( 0.872, 0.878)  1:( 0.607, 0.595) ||  Decision Tree\n",
      "Accuracy: 0.851 | AUROC 0.767 | (Accuracy, Precision) 0:( 0.926, 0.884)  1:( 0.608, 0.718) ||  Multi-layer Perceptron\n",
      "Accuracy: 0.861 | AUROC 0.769 | (Accuracy, Precision) 0:( 0.942, 0.883)  1:( 0.597, 0.761) ||  AdaBoost\n",
      "Accuracy: 0.856 | AUROC 0.769 | (Accuracy, Precision) 0:( 0.933, 0.885)  1:( 0.606, 0.736) ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueTestData(standardScalingTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821 | AUROC 0.685 | (Accuracy, Precision) 0:( 0.942, 0.842)  1:( 0.429, 0.695) ||  Logistic regression\n",
      "Accuracy: 0.801 | AUROC 0.660 | (Accuracy, Precision) 0:( 0.927, 0.832)  1:( 0.393, 0.625) ||  SGDClassifier\n",
      "Accuracy: 0.846 | AUROC 0.767 | (Accuracy, Precision) 0:( 0.916, 0.886)  1:( 0.617, 0.695) ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.802 | AUROC 0.618 | (Accuracy, Precision) 0:( 0.968, 0.810)  1:( 0.269, 0.719) ||  SVM-rbf\n",
      "Accuracy: 0.817 | AUROC 0.646 | (Accuracy, Precision) 0:( 0.970, 0.822)  1:( 0.323, 0.768) ||  Gaussian naive bayes\n",
      "Accuracy: 0.810 | AUROC 0.740 | (Accuracy, Precision) 0:( 0.872, 0.878)  1:( 0.608, 0.596) ||  Decision Tree\n",
      "Accuracy: 0.829 | AUROC 0.751 | (Accuracy, Precision) 0:( 0.899, 0.880)  1:( 0.603, 0.649) ||  Multi-layer Perceptron\n",
      "Accuracy: 0.861 | AUROC 0.769 | (Accuracy, Precision) 0:( 0.942, 0.883)  1:( 0.597, 0.761) ||  AdaBoost\n",
      "Accuracy: 0.853 | AUROC 0.766 | (Accuracy, Precision) 0:( 0.930, 0.883)  1:( 0.603, 0.727) ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueTestData(robustScalingTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 | AUROC 0.500 | (Accuracy, Precision) 0:( 1.000, 0.764)  1:( 0.000, 0.000) ||  Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.236 | AUROC 0.500 | (Accuracy, Precision) 0:( 0.000, 0.000)  1:( 1.000, 0.236) ||  SGDClassifier\n",
      "Accuracy: 0.721 | AUROC 0.536 | (Accuracy, Precision) 0:( 0.886, 0.779)  1:( 0.186, 0.336) ||  KNearest Neighbors (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764 | AUROC 0.500 | (Accuracy, Precision) 0:( 1.000, 0.764)  1:( 0.000, 0.000) ||  SVM-rbf\n",
      "Accuracy: 0.764 | AUROC 0.500 | (Accuracy, Precision) 0:( 1.000, 0.764)  1:( 0.000, 0.000) ||  Gaussian naive bayes\n",
      "Accuracy: 0.782 | AUROC 0.705 | (Accuracy, Precision) 0:( 0.851, 0.862)  1:( 0.559, 0.537) ||  Decision Tree\n",
      "Accuracy: 0.765 | AUROC 0.517 | (Accuracy, Precision) 0:( 0.987, 0.770)  1:( 0.047, 0.528) ||  Multi-layer Perceptron\n",
      "Accuracy: 0.838 | AUROC 0.744 | (Accuracy, Precision) 0:( 0.922, 0.873)  1:( 0.566, 0.691) ||  AdaBoost\n",
      "Accuracy: 0.815 | AUROC 0.724 | (Accuracy, Precision) 0:( 0.897, 0.866)  1:( 0.551, 0.622) ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueTestData(discretizeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782 | AUROC 0.542 | (Accuracy, Precision) 0:( 0.996, 0.779)  1:( 0.088, 0.885) ||  Logistic regression\n",
      "Accuracy: 0.779 | AUROC 0.534 | (Accuracy, Precision) 0:( 0.997, 0.776)  1:( 0.072, 0.890) ||  SGDClassifier\n",
      "Accuracy: 0.789 | AUROC 0.695 | (Accuracy, Precision) 0:( 0.873, 0.854)  1:( 0.516, 0.557) ||  KNearest Neighbors (5)\n",
      "Accuracy: 0.789 | AUROC 0.560 | (Accuracy, Precision) 0:( 0.994, 0.786)  1:( 0.126, 0.858) ||  SVM-rbf\n",
      "Accuracy: 0.794 | AUROC 0.575 | (Accuracy, Precision) 0:( 0.990, 0.792)  1:( 0.160, 0.830) ||  Gaussian naive bayes\n",
      "Accuracy: 0.790 | AUROC 0.721 | (Accuracy, Precision) 0:( 0.852, 0.871)  1:( 0.590, 0.552) ||  Decision Tree\n",
      "Accuracy: 0.797 | AUROC 0.597 | (Accuracy, Precision) 0:( 0.977, 0.801)  1:( 0.217, 0.744) ||  Multi-layer Perceptron\n",
      "Accuracy: 0.808 | AUROC 0.633 | (Accuracy, Precision) 0:( 0.965, 0.817)  1:( 0.302, 0.725) ||  AdaBoost\n",
      "Accuracy: 0.844 | AUROC 0.749 | (Accuracy, Precision) 0:( 0.929, 0.874)  1:( 0.569, 0.712) ||  Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechniqueTestData(normalizeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
