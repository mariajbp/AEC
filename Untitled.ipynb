{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, KBinsDiscretizer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, GenericUnivariateSelect, RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryClassification = pd.read_csv('data/training.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "salaryClassification = salaryClassification.replace(' ?', np.NaN)\n",
    "salaryClassification[' workclass'] = salaryClassification[' workclass'].replace(np.NaN, 'Unknown')\n",
    "salaryClassification[' occupation'] = salaryClassification[' occupation'].replace(np.NaN, 'Other')\n",
    "salaryClassification[' native-country'] = salaryClassification[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"workclass\"] = oe.fit_transform(salaryClassification[[\" workclass\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' workclass', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['fnlwgt'] = salaryClassification[' fnlwgt']\n",
    "salaryClassification = salaryClassification.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"education\"] = oe.fit_transform(salaryClassification[[\" education\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' education', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['education-num'] = salaryClassification[' education-num']\n",
    "salaryClassification = salaryClassification.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"marital-status\"] = oe.fit_transform(salaryClassification[[\" marital-status\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"occupation\"] = oe.fit_transform(salaryClassification[[\" occupation\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"relationship\"] = oe.fit_transform(salaryClassification[[\" relationship\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"race\"] = oe.fit_transform(salaryClassification[[\" race\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"sex\"] = oe.fit_transform(salaryClassification[[\" sex\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "salaryClassification['capital-diff'] = salaryClassification[' capital-gain'] - salaryClassification[' capital-loss']\n",
    "salaryClassification = salaryClassification.drop(' capital-gain', 1)\n",
    "salaryClassification = salaryClassification.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['hours-per-week'] = salaryClassification[' hours-per-week']\n",
    "salaryClassification = salaryClassification.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"native-county\"] = oe.fit_transform(salaryClassification[[\" native-country\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "salaryClassification[' salary-classification'] = [x.replace(' <=50K', '0') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = [x.replace(' >50K', '1') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = salaryClassification[' salary-classification'].astype(int)\n",
    "\n",
    "salaryClassification['salary-classification'] = salaryClassification[' salary-classification']\n",
    "salaryClassification = salaryClassification.drop(' salary-classification',1)\n",
    "\n",
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('data/test.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "testData = testData.replace(' ?', np.NaN)\n",
    "testData[' workclass'] = testData[' workclass'].replace(np.NaN, 'Unknown')\n",
    "testData[' occupation'] = testData[' occupation'].replace(np.NaN, 'Other')\n",
    "testData[' native-country'] = testData[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"workclass\"] = oe.fit_transform(testData[[\" workclass\"]]).astype(int)\n",
    "testData = testData.drop(' workclass', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['fnlwgt'] = testData[' fnlwgt']\n",
    "testData = testData.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"education\"] = oe.fit_transform(testData[[\" education\"]]).astype(int)\n",
    "testData = testData.drop(' education', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['education-num'] = testData[' education-num']\n",
    "testData = testData.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"marital-status\"] = oe.fit_transform(testData[[\" marital-status\"]]).astype(int)\n",
    "testData = testData.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"occupation\"] = oe.fit_transform(testData[[\" occupation\"]]).astype(int)\n",
    "testData = testData.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"relationship\"] = oe.fit_transform(testData[[\" relationship\"]]).astype(int)\n",
    "testData = testData.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"race\"] = oe.fit_transform(testData[[\" race\"]]).astype(int)\n",
    "testData = testData.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"sex\"] = oe.fit_transform(testData[[\" sex\"]]).astype(int)\n",
    "testData = testData.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "testData['capital-diff'] = testData[' capital-gain'] - testData[' capital-loss']\n",
    "testData = testData.drop(' capital-gain', 1)\n",
    "testData = testData.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['hours-per-week'] = testData[' hours-per-week']\n",
    "testData = testData.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"native-county\"] = oe.fit_transform(testData[[\" native-country\"]]).astype(int)\n",
    "testData = testData.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "testData[' salary-classification'] = [x.replace(' <=50K', '0') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = [x.replace(' >50K', '1') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = testData[' salary-classification'].astype(int)\n",
    "\n",
    "testData['salary-classification'] = testData[' salary-classification']\n",
    "testData = testData.drop(' salary-classification',1)\n",
    "\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScalingTest(train,test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( train )\n",
    "    scaled_test = scaler.transform(test)\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def discretizeTest(X_train, X_test):\n",
    "    ftd = ['age', 'hours-per-week', 'education-num', 'capital-diff']\n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    X_train[ftd] = discretizer.fit_transform(X_train[ftd])\n",
    "    X_test[ftd] = discretizer.transform(X_test[ftd])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def tomekSampler(X_train, y_train):\n",
    "    cc = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectKBest_f_classif(X_train, y_train, X_test):\n",
    "    kbest_selector_f_classif = SelectKBest(f_classif, k=7)\n",
    "    selector = kbest_selector_f_classif.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = kbest_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectKBest_chi2(X_train, y_train, X_test):\n",
    "    kbest_selector_chi2 = SelectKBest(chi2, k=7)\n",
    "    selector = kbest_selector_chi2.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_chi2.transform(X_train)\n",
    "    X_test_selected = kbest_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_f_classif(X_train, y_train, X_test):\n",
    "    percentile_selector_f_classif = SelectPercentile(f_classif, percentile=25)\n",
    "    selector = percentile_selector_f_classif.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = percentile_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_chi2(X_train, y_train, X_test):\n",
    "    percentile_selector_chi2 = SelectPercentile(chi2, percentile=25)\n",
    "    selector = percentile_selector_chi2.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_chi2.transform(X_train)\n",
    "    X_test_selected = percentile_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def selectVarianceThreshold(X_train, y_train, X_test):\n",
    "    varianceThreshold_selector = VarianceThreshold()\n",
    "    selector = varianceThreshold_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = varianceThreshold_selector.transform(X_train)\n",
    "    X_test_selected = varianceThreshold_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectGenericUnivariateSelect(X_train, y_train, X_test):\n",
    "    gus_selector = GenericUnivariateSelect(f_classif, 'k_best', param=14)\n",
    "    selector = gus_selector.fit(X_train, y_train)\n",
    "    X_train_selected = gus_selector.transform(X_train)\n",
    "    X_test_selected = gus_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(), 12)\n",
    "    selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def sfmTree(X_train, y_train, X_test):\n",
    "    tree_selector = ExtraTreesClassifier(n_estimators=50)\n",
    "    selector = tree_selector.fit(X_train, y_train)\n",
    "    sfm_Tree_selector = SelectFromModel(tree_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_Tree_selector.transform(X_train)\n",
    "    X_test_selected = sfm_Tree_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para grid search e aplicação das técnicas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test):        \n",
    "    clf = GridSearchCV(model, param_grid, refit=True, verbose=0)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(clf.best_params_)\n",
    "    predicted = clf.predict(X_test)\n",
    "    evaluateModel(modelName, y_test, predicted)\n",
    "    return ;\n",
    "    \n",
    "    \n",
    "def apllyGridSearchWithTransformation(model, transformer, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def apllyGridSearchWithFSelect(model, transformer, selector, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "def apllyGridSearchWithLoadBalancing(model, transformer, selector, balancer, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, y_train = balancer(X_train, y_train)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "\n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8eeaa5c7eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m } \n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mapllyGridSearchWithLoadBalancing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscretizeTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselectVarianceThreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtomekSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid_svc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid_svc = {\n",
    "    'class_weight': ['balanced', None], \n",
    "    'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "     'kernel': ['rbf']\n",
    "} \n",
    "\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretizeTest, selectVarianceThreshold, tomekSampler, param_grid_svc, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVC com robust scaling + select variance threshold + tomekSampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), robustScalingTest, selectPercentile_f_classif, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectPercentile_chi2 + tomeSampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretize2, selectPercentile_chi2, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectVarianceThreshold + tomekSampler:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.647 || AUROC 0.592 || (Accuracy, Precision) 0:( 0.696, 0.815)  1:( 0.489, 0.332) -> knn\n",
      "{'metric': 'manhattan', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "Accuracy: 0.737 || AUROC 0.601 || (Accuracy, Precision) 0:( 0.859, 0.809)  1:( 0.343, 0.429) -> knn\n",
      "{'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "Accuracy: 0.811 || AUROC 0.757 || (Accuracy, Precision) 0:( 0.860, 0.889)  1:( 0.654, 0.591) -> knn\n"
     ]
    }
   ],
   "source": [
    "grid_params_knn = {\n",
    "    'n_neighbors' : [3,5,7,11,13, 15, 17, 25, 30, 50],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectPercentile_chi2, overSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectPercentile_chi2, tomekSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectKBest_f_classif, tomekSampler, grid_params_knn, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.809 || AUROC 0.740 || (Accuracy, Precision) 0:( 0.871, 0.878)  1:( 0.608, 0.594) -> DecisionTree\n"
     ]
    }
   ],
   "source": [
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_mlp = {\n",
    "    'solver': ['adam'],\n",
    "    'activation': ['identity', 'logistic','tanh'],\n",
    "    'max_iter': [1000],\n",
    "    'shuffle': [True],\n",
    "    'alpha': 10.0 ** -np.arange(3, 7),\n",
    "    'hidden_layer_sizes': [100, 150, 200],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(MLPClassifier(), discretizeTest, selectPercentile_chi2, overSampler, grid_params_mlp, \"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Accuracy: 0.741 || AUROC 0.678 || (Accuracy, Precision) 0:( 0.798, 0.854)  1:( 0.557, 0.461) -> AdaBoost\n"
     ]
    }
   ],
   "source": [
    "grid_params_adaboost = {\n",
    "     'n_estimators' : [10,20,30,50,100,200,1000],\n",
    "      'learning_rate':[.001,0.01,.1],  \n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(AdaBoostClassifier(), discretizeTest, selectPercentile_chi2, tomekSampler, grid_params_adaboost, \"AdaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 20, 'n_estimators': 100}\n",
      "Accuracy: 0.745 || AUROC 0.658 || (Accuracy, Precision) 0:( 0.822, 0.840)  1:( 0.493, 0.462) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "grid_params_randomforest = {\n",
    "     'n_estimators' : [10,20,30,50,100,200,1000],\n",
    "    'max_depth' : [1, 10, 20, None],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(RandomForestClassifier(), discretizeTest, selectPercentile_chi2, tomekSampler, grid_params_randomforest, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']\n",
    "\n",
    "X_train, X_test = discretize2(X_train, X_test)\n",
    "X_train, X_test = selectPercentile_chi2(X_train, y_train, X_test)\n",
    "X_train, y_train = tokenSampler(X_train, y_train)\n",
    "\n",
    "clf1 = SVC(C= 100, class_weight = 'balanced', gamma= 0.1, kernel= 'rbf')\n",
    "clf2 = KNeighborsClassifier(metric= 'manhattan', n_neighbors = 17, weights = 'distance')\n",
    "clf3 = DecisionTreeClassifier()\n",
    "clf4 = AdaBoostClassifier()\n",
    "clf5 = RandomForestClassifier(bootstrap= True, max_depth= 20, n_estimators= 1000)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), ('svc', clf2), ('knn', clf3), ('cnb', clf4), ('rfc', clf5)], voting='hard')\n",
    "\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "predicted = eclf1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"voting classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
