{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, KBinsDiscretizer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, GenericUnivariateSelect, RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryClassification = pd.read_csv('data/training.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "salaryClassification = salaryClassification.replace(' ?', np.NaN)\n",
    "salaryClassification[' workclass'] = salaryClassification[' workclass'].replace(np.NaN, 'Unknown')\n",
    "salaryClassification[' occupation'] = salaryClassification[' occupation'].replace(np.NaN, 'Other')\n",
    "salaryClassification[' native-country'] = salaryClassification[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"workclass\"] = oe.fit_transform(salaryClassification[[\" workclass\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' workclass', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['fnlwgt'] = salaryClassification[' fnlwgt']\n",
    "salaryClassification = salaryClassification.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"education\"] = oe.fit_transform(salaryClassification[[\" education\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' education', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['education-num'] = salaryClassification[' education-num']\n",
    "salaryClassification = salaryClassification.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"marital-status\"] = oe.fit_transform(salaryClassification[[\" marital-status\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"occupation\"] = oe.fit_transform(salaryClassification[[\" occupation\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"relationship\"] = oe.fit_transform(salaryClassification[[\" relationship\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"race\"] = oe.fit_transform(salaryClassification[[\" race\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"sex\"] = oe.fit_transform(salaryClassification[[\" sex\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "salaryClassification['capital-diff'] = salaryClassification[' capital-gain'] - salaryClassification[' capital-loss']\n",
    "salaryClassification = salaryClassification.drop(' capital-gain', 1)\n",
    "salaryClassification = salaryClassification.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column names\n",
    "salaryClassification['hours-per-week'] = salaryClassification[' hours-per-week']\n",
    "salaryClassification = salaryClassification.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"native-county\"] = oe.fit_transform(salaryClassification[[\" native-country\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "salaryClassification[' salary-classification'] = [x.replace(' <=50K', '0') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = [x.replace(' >50K', '1') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = salaryClassification[' salary-classification'].astype(int)\n",
    "\n",
    "salaryClassification['salary-classification'] = salaryClassification[' salary-classification']\n",
    "salaryClassification = salaryClassification.drop(' salary-classification',1)\n",
    "\n",
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('data/test.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "testData = testData.replace(' ?', np.NaN)\n",
    "testData[' workclass'] = testData[' workclass'].replace(np.NaN, 'Unknown')\n",
    "testData[' occupation'] = testData[' occupation'].replace(np.NaN, 'Other')\n",
    "testData[' native-country'] = testData[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"workclass\"] = oe.fit_transform(testData[[\" workclass\"]]).astype(int)\n",
    "testData = testData.drop(' workclass', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['fnlwgt'] = testData[' fnlwgt']\n",
    "testData = testData.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"education\"] = oe.fit_transform(testData[[\" education\"]]).astype(int)\n",
    "testData = testData.drop(' education', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['education-num'] = testData[' education-num']\n",
    "testData = testData.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"marital-status\"] = oe.fit_transform(testData[[\" marital-status\"]]).astype(int)\n",
    "testData = testData.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"occupation\"] = oe.fit_transform(testData[[\" occupation\"]]).astype(int)\n",
    "testData = testData.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"relationship\"] = oe.fit_transform(testData[[\" relationship\"]]).astype(int)\n",
    "testData = testData.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"race\"] = oe.fit_transform(testData[[\" race\"]]).astype(int)\n",
    "testData = testData.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"sex\"] = oe.fit_transform(testData[[\" sex\"]]).astype(int)\n",
    "testData = testData.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "testData['capital-diff'] = testData[' capital-gain'] - testData[' capital-loss']\n",
    "testData = testData.drop(' capital-gain', 1)\n",
    "testData = testData.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['hours-per-week'] = testData[' hours-per-week']\n",
    "testData = testData.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"native-county\"] = oe.fit_transform(testData[[\" native-country\"]]).astype(int)\n",
    "testData = testData.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "testData[' salary-classification'] = [x.replace(' <=50K', '0') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = [x.replace(' >50K', '1') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = testData[' salary-classification'].astype(int)\n",
    "\n",
    "testData['salary-classification'] = testData[' salary-classification']\n",
    "testData = testData.drop(' salary-classification',1)\n",
    "\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScalingTest(train,test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( train )\n",
    "    scaled_test = scaler.transform(test)\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def discretizeTest(X_train, X_test):\n",
    "    ftd = ['age', 'hours-per-week', 'education-num', 'capital-diff']\n",
    "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    X_train[ftd] = discretizer.fit_transform(X_train[ftd])\n",
    "    X_test[ftd] = discretizer.transform(X_test[ftd])\n",
    "    return X_train, X_test;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def smotetomekSampler(X_train, y_train):\n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    X_balanced, y_train = smote_tomek.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectKBest_f_classif(X_train, y_train, X_test):\n",
    "    kbest_selector_f_classif = SelectKBest(f_classif, k=7)\n",
    "    selector = kbest_selector_f_classif.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = kbest_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectKBest_chi2(X_train, y_train, X_test):\n",
    "    kbest_selector_chi2 = SelectKBest(chi2, k=7)\n",
    "    selector = kbest_selector_chi2.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_chi2.transform(X_train)\n",
    "    X_test_selected = kbest_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_f_classif(X_train, y_train, X_test):\n",
    "    percentile_selector_f_classif = SelectPercentile(f_classif, percentile=25)\n",
    "    selector = percentile_selector_f_classif.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = percentile_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_chi2(X_train, y_train, X_test):\n",
    "    percentile_selector_chi2 = SelectPercentile(chi2, percentile=25)\n",
    "    selector = percentile_selector_chi2.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_chi2.transform(X_train)\n",
    "    X_test_selected = percentile_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def selectVarianceThreshold(X_train, y_train, X_test):\n",
    "    varianceThreshold_selector = VarianceThreshold()\n",
    "    selector = varianceThreshold_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = varianceThreshold_selector.transform(X_train)\n",
    "    X_test_selected = varianceThreshold_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectGenericUnivariateSelect(X_train, y_train, X_test):\n",
    "    gus_selector = GenericUnivariateSelect(f_classif, 'k_best', param=14)\n",
    "    selector = gus_selector.fit(X_train, y_train)\n",
    "    X_train_selected = gus_selector.transform(X_train)\n",
    "    X_test_selected = gus_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(), 12)\n",
    "    selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def sfmTree(X_train, y_train, X_test):\n",
    "    tree_selector = ExtraTreesClassifier(n_estimators=50)\n",
    "    selector = tree_selector.fit(X_train, y_train)\n",
    "    sfm_Tree_selector = SelectFromModel(tree_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_Tree_selector.transform(X_train)\n",
    "    X_test_selected = sfm_Tree_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções para grid search e aplicação das técnicas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test):        \n",
    "    clf = GridSearchCV(model, param_grid, refit=True, verbose=0)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(clf.best_params_)\n",
    "    predicted = clf.predict(X_test)\n",
    "    evaluateModel(modelName, y_test, predicted)\n",
    "    return ;\n",
    "    \n",
    "    \n",
    "def apllyGridSearchWithTransformation(model, transformer, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def apllyGridSearchWithFSelect(model, transformer, selector, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "    \n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "def apllyGridSearchWithLoadBalancing(model, transformer, selector, balancer, param_grid, modelName):\n",
    "    X_train = salaryClassification.drop('salary-classification', 1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification', 1)\n",
    "    y_test =  testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = transformer(X_train, X_test)\n",
    "    X_train, y_train = balancer(X_train, y_train)\n",
    "    X_train, X_test = selector(X_train, y_train, X_test)\n",
    "\n",
    "    gridSearch(model, param_grid, modelName, X_train, y_train, X_test, y_test)\n",
    "    return ;\n",
    "\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {\n",
    "    'class_weight': ['balanced', None], \n",
    "    'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001]\n",
    "} \n",
    "\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretizeTest, selectVarianceThreshold, overSampler, param_grid_svc, \"SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVC com robust scaling + select variance threshold + smoteenSampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), robustScalingTest, selectPercentile_f_classif, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectPercentile_chi2 + over sampler:\")\n",
    "apllyGridSearchWithLoadBalancing(SVC(), discretize2, selectPercentile_chi2, overSampler, param_grid_svc, \"SVC\")\n",
    "print(\"SVC com discretizacao e select selectVarianceThreshold + over sampler:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 10, 'n_estimators': 20}\n",
      "Accuracy: 0.708 || AUROC 0.772 || (Accuracy, Precision) 0:( 0.652, 0.951)  1:( 0.892, 0.442) -> Random Forest\n",
      "{'bootstrap': True, 'max_depth': None, 'n_estimators': 1000}\n",
      "Accuracy: 0.729 || AUROC 0.658 || (Accuracy, Precision) 0:( 0.793, 0.843)  1:( 0.523, 0.439) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "grid_params_randomforest = {\n",
    "    'n_estimators' : [10,20,30,50,100,200,1000],\n",
    "    'max_depth' : [1, 10, 20, None],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(RandomForestClassifier(), discretizeTest, selectPercentile_f_classif, overSampler, grid_params_randomforest, \"Random Forest\")\n",
    "apllyGridSearchWithLoadBalancing(RandomForestClassifier(), discretizeTest, selectPercentile_chi2, overSampler, grid_params_randomforest, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811 || AUROC 0.742 || (Accuracy, Precision) 0:( 0.873, 0.879)  1:( 0.612, 0.599) -> DecisionTree\n"
     ]
    }
   ],
   "source": [
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.646 || AUROC 0.590 || (Accuracy, Precision) 0:( 0.697, 0.813)  1:( 0.483, 0.330) -> knn\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.629 || AUROC 0.569 || (Accuracy, Precision) 0:( 0.682, 0.802)  1:( 0.457, 0.308) -> knn\n",
      "{'metric': 'manhattan', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "Accuracy: 0.784 || AUROC 0.768 || (Accuracy, Precision) 0:( 0.798, 0.908)  1:( 0.738, 0.530) -> knn\n"
     ]
    }
   ],
   "source": [
    "grid_params_knn = {\n",
    "    'n_neighbors' : [3,5,7,11,13, 15, 17, 25, 30, 50],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectPercentile_chi2, overSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectPercentile_chi2, smotetomekSampler, grid_params_knn, \"knn\")\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(KNeighborsClassifier(), discretizeTest, selectKBest_f_classif, overSampler, grid_params_knn, \"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'identity', 'alpha': 1e-06, 'hidden_layer_sizes': 200, 'max_iter': 1000, 'shuffle': True, 'solver': 'adam'}\n",
      "Accuracy: 0.764 || AUROC 0.500 || (Accuracy, Precision) 0:( 1.000, 0.764)  1:( 0.000, 0.000) -> mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid_params_mlp = {\n",
    "    'solver': ['adam'],\n",
    "    'activation': ['identity', 'logistic','tanh'],\n",
    "    'max_iter': [1000],\n",
    "    'shuffle': [True],\n",
    "    'alpha': 10.0 ** -np.arange(3, 7),\n",
    "    'hidden_layer_sizes': [100, 150, 200],\n",
    "}\n",
    "\n",
    "apllyGridSearchWithLoadBalancing(MLPClassifier(), discretizeTest, selectPercentile_chi2, overSampler, grid_params_mlp, \"mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1490400 is out of bounds for axis 1 with size 1484706",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b3077b08c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n\u001b[1;32m     14\u001b[0m               % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mjll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1490400 is out of bounds for axis 1 with size 1484706"
     ]
    }
   ],
   "source": [
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']\n",
    "\n",
    "X_train, X_test = discretizeTest(X_train, X_test)\n",
    "X_train, X_test = selectPercentile_chi2(X_train, y_train, X_test)\n",
    "X_train, y_train = overSampler(X_train, y_train)\n",
    "\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"categoricalnb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = salaryClassification.drop('salary-classification', 1)\n",
    "y_train =  salaryClassification['salary-classification']\n",
    "X_test = testData.drop('salary-classification', 1)\n",
    "y_test =  testData['salary-classification']\n",
    "\n",
    "X_train, X_test = discretize2(X_train, X_test)\n",
    "X_train, X_test = selectPercentile_chi2(X_train, y_train, X_test)\n",
    "X_train, y_train = overSampler(X_train, y_train)\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = SVC(C= 100, class_weight = 'balanced', gamma= 0.1, kernel= 'rbf')\n",
    "clf3 = KNeighborsClassifier(metric= 'manhattan', n_neighbors = 17, weights = 'distance')\n",
    "clf4 = CategoricalNB()\n",
    "clf5 = RandomForestClassifier(bootstrap= False, max_depth= 10, n_estimators= 2000)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), ('svc', clf2), ('knn', clf3), ('cnb', clf4), ('rfc', clf5)], voting='hard')\n",
    "\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "predicted = eclf1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), \"voting classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
