{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, accuracy_score, roc_auc_score\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore')\n",
    "from sklearn.exceptions import ConvergenceWarning, NotFittedError, ChangedBehaviorWarning,ConvergenceWarning,DataConversionWarning,DataDimensionalityWarning,EfficiencyWarning,FitFailedWarning,NonBLASDotWarning,SkipTestWarning,UndefinedMetricWarning,PositiveSpectrumWarning\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryClassification = pd.read_csv('data/training.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "salaryClassification = salaryClassification.replace(' ?', np.NaN)\n",
    "salaryClassification[' workclass'] = salaryClassification[' workclass'].replace(np.NaN, 'Unknown')\n",
    "salaryClassification[' occupation'] = salaryClassification[' occupation'].replace(np.NaN, 'Other')\n",
    "salaryClassification[' native-country'] = salaryClassification[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"workclass\"] = oe.fit_transform(salaryClassification[[\" workclass\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' workclass', 1)\n",
    "\n",
    "#fix column name\n",
    "salaryClassification['fnlwgt'] = salaryClassification[' fnlwgt']\n",
    "salaryClassification = salaryClassification.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"education\"] = oe.fit_transform(salaryClassification[[\" education\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' education', 1)\n",
    "\n",
    "#fix column name\n",
    "salaryClassification['education-num'] = salaryClassification[' education-num']\n",
    "salaryClassification = salaryClassification.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"marital-status\"] = oe.fit_transform(salaryClassification[[\" marital-status\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"occupation\"] = oe.fit_transform(salaryClassification[[\" occupation\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"relationship\"] = oe.fit_transform(salaryClassification[[\" relationship\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"race\"] = oe.fit_transform(salaryClassification[[\" race\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"sex\"] = oe.fit_transform(salaryClassification[[\" sex\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "salaryClassification['capital-diff'] = salaryClassification[' capital-gain'] - salaryClassification[' capital-loss']\n",
    "salaryClassification = salaryClassification.drop(' capital-gain', 1)\n",
    "salaryClassification = salaryClassification.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column name\n",
    "salaryClassification['hours-per-week'] = salaryClassification[' hours-per-week']\n",
    "salaryClassification = salaryClassification.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "salaryClassification[\"native-county\"] = oe.fit_transform(salaryClassification[[\" native-country\"]]).astype(int)\n",
    "salaryClassification = salaryClassification.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "salaryClassification[' salary-classification'] = [x.replace(' <=50K', '0') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = [x.replace(' >50K', '1') for x in salaryClassification[' salary-classification']]\n",
    "salaryClassification[' salary-classification'] = salaryClassification[' salary-classification'].astype(int)\n",
    "salaryClassification['salary-classification'] = salaryClassification[' salary-classification']\n",
    "salaryClassification = salaryClassification.drop(' salary-classification',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv('data/test.csv', sep = ';')\n",
    "\n",
    "#treat missing values\n",
    "testData = testData.replace(' ?', np.NaN)\n",
    "testData[' workclass'] = testData[' workclass'].replace(np.NaN, 'Unknown')\n",
    "testData[' occupation'] = testData[' occupation'].replace(np.NaN, 'Other')\n",
    "testData[' native-country'] = testData[' native-country'].replace(np.NaN, 'Other')\n",
    "\n",
    "\n",
    "#convert 'workclass' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"workclass\"] = oe.fit_transform(testData[[\" workclass\"]]).astype(int)\n",
    "testData = testData.drop(' workclass', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['fnlwgt'] = testData[' fnlwgt']\n",
    "testData = testData.drop(' fnlwgt',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"education\"] = oe.fit_transform(testData[[\" education\"]]).astype(int)\n",
    "testData = testData.drop(' education', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['education-num'] = testData[' education-num']\n",
    "testData = testData.drop(' education-num',1)\n",
    "\n",
    "#convert 'education' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"marital-status\"] = oe.fit_transform(testData[[\" marital-status\"]]).astype(int)\n",
    "testData = testData.drop(' marital-status', 1)\n",
    "\n",
    "#convert 'occupation'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"occupation\"] = oe.fit_transform(testData[[\" occupation\"]]).astype(int)\n",
    "testData = testData.drop(' occupation', 1)\n",
    "\n",
    "#convert 'relationship'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"relationship\"] = oe.fit_transform(testData[[\" relationship\"]]).astype(int)\n",
    "testData = testData.drop(' relationship', 1)\n",
    "\n",
    "#convert 'race'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"race\"] = oe.fit_transform(testData[[\" race\"]]).astype(int)\n",
    "testData = testData.drop(' race', 1)\n",
    "\n",
    "#convert 'sex'n' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"sex\"] = oe.fit_transform(testData[[\" sex\"]]).astype(int)\n",
    "testData = testData.drop(' sex', 1)\n",
    "\n",
    "#join 2 columns(capital-gain and  capital-loss) in one\n",
    "testData['capital-diff'] = testData[' capital-gain'] - testData[' capital-loss']\n",
    "testData = testData.drop(' capital-gain', 1)\n",
    "testData = testData.drop(' capital-loss', 1)\n",
    "\n",
    "#fix column name\n",
    "testData['hours-per-week'] = testData[' hours-per-week']\n",
    "testData = testData.drop(' hours-per-week',1)\n",
    "\n",
    "\n",
    "#convert 'native-country' from categorical to numeric\n",
    "oe = OrdinalEncoder()\n",
    "testData[\"native-county\"] = oe.fit_transform(testData[[\" native-country\"]]).astype(int)\n",
    "testData = testData.drop(' native-country', 1)\n",
    "\n",
    "\n",
    "#convert salary-classification' from categorical to numeric\n",
    "testData[' salary-classification'] = [x.replace(' <=50K', '0') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = [x.replace(' >50K', '1') for x in testData[' salary-classification']]\n",
    "testData[' salary-classification'] = testData[' salary-classification'].astype(int)\n",
    "\n",
    "testData['salary-classification'] = testData[' salary-classification']\n",
    "testData = testData.drop(' salary-classification',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteSampler(X_train, y_train):\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    X_balanced, y_train = smote.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;### Up-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sample minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def underSampler(X_train, y_train):\n",
    "    rus = RandomUnderSampler()\n",
    "    X_balanced, y_train = rus.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroidSampler(X_train, y_train):\n",
    "    cc = ClusterCentroids(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomekSampler(X_train, y_train):\n",
    "    cc = TomekLinks(sampling_strategy='majority')\n",
    "    X_balanced, y_train = cc.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of over- and under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteeenSampler(X_train, y_train):\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_balanced, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das diferentes técnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling(X_train):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    return scaled_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTechnique(balancer):\n",
    "    X_train = salaryClassification.drop('salary-classification',1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "\n",
    "    X_train = robustScaling(X_train)\n",
    "    \n",
    "    X_train, y_train = balancer(X_train, y_train)\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=10000,class_weight='balanced'),\n",
    "        SGDClassifier(class_weight='balanced'),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(max_iter=10000,class_weight='balanced'),\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(class_weight='balanced'),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(class_weight='balanced'),\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors(5)\", \n",
    "             \"SVM-rbf\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "\n",
    "    metrics = {'recall0': make_scorer(recall_score, pos_label = 0), \n",
    "               'recall1': make_scorer(recall_score, pos_label = 1),\n",
    "               'precision0': make_scorer(precision_score, pos_label = 0),\n",
    "               'precision1': make_scorer(precision_score, pos_label = 0),\n",
    "               'accuracy' : 'accuracy',\n",
    "               'roc_auc': 'roc_auc'\n",
    "              }\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_validate(clf, X_train, y_train, cv=10, scoring=metrics)\n",
    "        print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (scores['test_accuracy'].mean(), scores['test_roc_auc'].mean(),\n",
    "                scores['test_recall0'].mean(), scores['test_precision0'].mean(),\n",
    "                scores['test_recall1'].mean(), scores['test_precision1'].mean()), name)\n",
    "        \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.765 || AUROC 0.845 || (Accuracy, Precision) 0:( 0.759, 0.768)  1:( 0.771, 0.768) -> Logistic regression\n",
      "Accuracy: 0.717 || AUROC 0.744 || (Accuracy, Precision) 0:( 0.732, 0.712)  1:( 0.702, 0.712) -> SGDClassifier\n",
      "Accuracy: 0.854 || AUROC 0.925 || (Accuracy, Precision) 0:( 0.789, 0.907)  1:( 0.919, 0.907) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.512 || AUROC 0.755 || (Accuracy, Precision) 0:( 0.083, 0.361)  1:( 0.940, 0.361) -> SVM-rbf\n",
      "Accuracy: 0.704 || AUROC 0.858 || (Accuracy, Precision) 0:( 0.943, 0.638)  1:( 0.465, 0.638) -> Gaussian naive bayes\n",
      "Accuracy: 0.925 || AUROC 0.925 || (Accuracy, Precision) 0:( 0.870, 0.977)  1:( 0.979, 0.977) -> Decision Tree\n",
      "Accuracy: 0.815 || AUROC 0.894 || (Accuracy, Precision) 0:( 0.779, 0.840)  1:( 0.852, 0.840) -> Multi-layer Perceptron\n",
      "Accuracy: 0.829 || AUROC 0.916 || (Accuracy, Precision) 0:( 0.813, 0.841)  1:( 0.846, 0.841) -> AdaBoost\n",
      "Accuracy: 0.937 || AUROC 0.989 || (Accuracy, Precision) 0:( 0.892, 0.980)  1:( 0.982, 0.980) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.766 || AUROC 0.848 || (Accuracy, Precision) 0:( 0.756, 0.771)  1:( 0.776, 0.771) -> Logistic regression\n",
      "Accuracy: 0.721 || AUROC 0.745 || (Accuracy, Precision) 0:( 0.735, 0.715)  1:( 0.706, 0.715) -> SGDClassifier\n",
      "Accuracy: 0.871 || AUROC 0.936 || (Accuracy, Precision) 0:( 0.801, 0.932)  1:( 0.941, 0.932) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.522 || AUROC 0.789 || (Accuracy, Precision) 0:( 0.067, 0.629)  1:( 0.977, 0.629) -> SVM-rbf\n",
      "Accuracy: 0.730 || AUROC 0.864 || (Accuracy, Precision) 0:( 0.930, 0.664)  1:( 0.530, 0.664) -> Gaussian naive bayes\n",
      "Accuracy: 0.860 || AUROC 0.861 || (Accuracy, Precision) 0:( 0.856, 0.863)  1:( 0.865, 0.863) -> Decision Tree\n",
      "Accuracy: 0.818 || AUROC 0.893 || (Accuracy, Precision) 0:( 0.780, 0.844)  1:( 0.856, 0.844) -> Multi-layer Perceptron\n",
      "Accuracy: 0.853 || AUROC 0.935 || (Accuracy, Precision) 0:( 0.827, 0.872)  1:( 0.879, 0.872) -> AdaBoost\n",
      "Accuracy: 0.904 || AUROC 0.966 || (Accuracy, Precision) 0:( 0.895, 0.911)  1:( 0.913, 0.911) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(smoteSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.762 || AUROC 0.844 || (Accuracy, Precision) 0:( 0.754, 0.767)  1:( 0.771, 0.767) -> Logistic regression\n",
      "Accuracy: 0.703 || AUROC 0.727 || (Accuracy, Precision) 0:( 0.705, 0.703)  1:( 0.701, 0.703) -> SGDClassifier\n",
      "Accuracy: 0.806 || AUROC 0.883 || (Accuracy, Precision) 0:( 0.781, 0.823)  1:( 0.832, 0.823) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.605 || AUROC 0.817 || (Accuracy, Precision) 0:( 0.771, 0.463)  1:( 0.438, 0.463) -> SVM-rbf\n",
      "Accuracy: 0.689 || AUROC 0.857 || (Accuracy, Precision) 0:( 0.946, 0.625)  1:( 0.433, 0.625) -> Gaussian naive bayes\n",
      "Accuracy: 0.771 || AUROC 0.771 || (Accuracy, Precision) 0:( 0.770, 0.772)  1:( 0.773, 0.772) -> Decision Tree\n",
      "Accuracy: 0.795 || AUROC 0.868 || (Accuracy, Precision) 0:( 0.770, 0.812)  1:( 0.819, 0.812) -> Multi-layer Perceptron\n",
      "Accuracy: 0.826 || AUROC 0.915 || (Accuracy, Precision) 0:( 0.807, 0.839)  1:( 0.844, 0.839) -> AdaBoost\n",
      "Accuracy: 0.820 || AUROC 0.907 || (Accuracy, Precision) 0:( 0.803, 0.830)  1:( 0.836, 0.830) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(underSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.762 || AUROC 0.836 || (Accuracy, Precision) 0:( 0.733, 0.779)  1:( 0.792, 0.779) -> Logistic regression\n",
      "Accuracy: 0.703 || AUROC 0.700 || (Accuracy, Precision) 0:( 0.701, 0.704)  1:( 0.704, 0.704) -> SGDClassifier\n",
      "Accuracy: 0.834 || AUROC 0.892 || (Accuracy, Precision) 0:( 0.802, 0.857)  1:( 0.866, 0.857) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.576 || AUROC 0.753 || (Accuracy, Precision) 0:( 0.749, 0.555)  1:( 0.403, 0.555) -> SVM-rbf\n",
      "Accuracy: 0.784 || AUROC 0.853 || (Accuracy, Precision) 0:( 0.838, 0.757)  1:( 0.731, 0.757) -> Gaussian naive bayes\n",
      "Accuracy: 0.835 || AUROC 0.835 || (Accuracy, Precision) 0:( 0.824, 0.842)  1:( 0.845, 0.842) -> Decision Tree\n",
      "Accuracy: 0.793 || AUROC 0.848 || (Accuracy, Precision) 0:( 0.770, 0.810)  1:( 0.815, 0.810) -> Multi-layer Perceptron\n",
      "Accuracy: 0.869 || AUROC 0.943 || (Accuracy, Precision) 0:( 0.859, 0.877)  1:( 0.879, 0.877) -> AdaBoost\n",
      "Accuracy: 0.878 || AUROC 0.953 || (Accuracy, Precision) 0:( 0.871, 0.883)  1:( 0.884, 0.883) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(centroidSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847 || AUROC 0.922 || (Accuracy, Precision) 0:( 0.842, 0.833)  1:( 0.851, 0.833) -> Logistic regression\n",
      "Accuracy: 0.781 || AUROC 0.786 || (Accuracy, Precision) 0:( 0.784, 0.758)  1:( 0.778, 0.758) -> SGDClassifier\n",
      "Accuracy: 0.976 || AUROC 0.995 || (Accuracy, Precision) 0:( 0.959, 0.989)  1:( 0.991, 0.989) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.533 || AUROC 0.719 || (Accuracy, Precision) 0:( 0.000, 0.000)  1:( 1.000, 0.000) -> SVM-rbf\n",
      "Accuracy: 0.837 || AUROC 0.929 || (Accuracy, Precision) 0:( 0.936, 0.767)  1:( 0.750, 0.767) -> Gaussian naive bayes\n",
      "Accuracy: 0.947 || AUROC 0.947 || (Accuracy, Precision) 0:( 0.940, 0.947)  1:( 0.954, 0.947) -> Decision Tree\n",
      "Accuracy: 0.909 || AUROC 0.956 || (Accuracy, Precision) 0:( 0.883, 0.920)  1:( 0.932, 0.920) -> Multi-layer Perceptron\n",
      "Accuracy: 0.933 || AUROC 0.983 || (Accuracy, Precision) 0:( 0.915, 0.939)  1:( 0.948, 0.939) -> AdaBoost\n",
      "Accuracy: 0.968 || AUROC 0.995 || (Accuracy, Precision) 0:( 0.956, 0.974)  1:( 0.978, 0.974) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(smoteeenSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.771 || AUROC 0.856 || (Accuracy, Precision) 0:( 0.768, 0.912)  1:( 0.781, 0.912) -> Logistic regression\n",
      "Accuracy: 0.720 || AUROC 0.733 || (Accuracy, Precision) 0:( 0.726, 0.879)  1:( 0.703, 0.879) -> SGDClassifier\n",
      "Accuracy: 0.865 || AUROC 0.900 || (Accuracy, Precision) 0:( 0.923, 0.898)  1:( 0.690, 0.898) -> KNearest Neighbors(5)\n",
      "Accuracy: 0.252 || AUROC 0.757 || (Accuracy, Precision) 0:( 0.000, 0.000)  1:( 1.000, 0.000) -> SVM-rbf\n",
      "Accuracy: 0.815 || AUROC 0.870 || (Accuracy, Precision) 0:( 0.967, 0.819)  1:( 0.364, 0.819) -> Gaussian naive bayes\n",
      "Accuracy: 0.835 || AUROC 0.781 || (Accuracy, Precision) 0:( 0.889, 0.890)  1:( 0.674, 0.890) -> Decision Tree\n",
      "Accuracy: 0.843 || AUROC 0.894 || (Accuracy, Precision) 0:( 0.920, 0.876)  1:( 0.613, 0.876) -> Multi-layer Perceptron\n",
      "Accuracy: 0.870 || AUROC 0.926 || (Accuracy, Precision) 0:( 0.941, 0.891)  1:( 0.659, 0.891) -> AdaBoost\n",
      "Accuracy: 0.877 || AUROC 0.928 || (Accuracy, Precision) 0:( 0.941, 0.899)  1:( 0.687, 0.899) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateTechnique(tomekSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling2(X_train, X_test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    scaled_test = scaler.transform( X_test )\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def discretize2(X_train, X_test):\n",
    "    featuresToDiscretize = ['age', 'hours-per-week', 'education-num', 'capital-diff']\n",
    "    discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "    X_train[featuresToDiscretize] = discretizer.fit_transform(X_train[featuresToDiscretize])\n",
    "    X_test[featuresToDiscretize] = discretizer.transform(X_test[featuresToDiscretize])\n",
    "    return X_train, X_test;\n",
    "\n",
    "def evaluateBalancerAgaintTestData(balancer):\n",
    "    X_train = salaryClassification.drop('salary-classification',1)\n",
    "    y_train =  salaryClassification['salary-classification']\n",
    "    X_test = testData.drop('salary-classification',1)\n",
    "    y_test = testData['salary-classification']\n",
    "    \n",
    "    X_train, X_test = robustScaling2(X_train, X_test)\n",
    "    \n",
    "    X_train, y_train = balancer(X_train, y_train)\n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(max_iter=10000,class_weight='balanced'),\n",
    "        SGDClassifier(class_weight='balanced'),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(max_iter=10000,class_weight='balanced'),\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(class_weight='balanced'),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(class_weight='balanced'),\n",
    "    ]\n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "        \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755 || AUROC 0.755 || (Accuracy, Precision) 0:( 0.755, 0.909)  1:( 0.756, 0.488) -> Logistic regression\n",
      "Accuracy: 0.731 || AUROC 0.722 || (Accuracy, Precision) 0:( 0.739, 0.890)  1:( 0.705, 0.455) -> SGDClassifier\n",
      "Accuracy: 0.793 || AUROC 0.796 || (Accuracy, Precision) 0:( 0.790, 0.928)  1:( 0.802, 0.541) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.229 || AUROC 0.485 || (Accuracy, Precision) 0:( 0.000, 0.017)  1:( 0.970, 0.231) -> SVM-rbf\n",
      "Accuracy: 0.827 || AUROC 0.701 || (Accuracy, Precision) 0:( 0.940, 0.850)  1:( 0.462, 0.704) -> Gaussian naive bayes\n",
      "Accuracy: 0.813 || AUROC 0.740 || (Accuracy, Precision) 0:( 0.878, 0.877)  1:( 0.601, 0.605) -> Decision Tree\n",
      "Accuracy: 0.791 || AUROC 0.808 || (Accuracy, Precision) 0:( 0.775, 0.941)  1:( 0.842, 0.536) -> Multi-layer Perceptron\n",
      "Accuracy: 0.820 || AUROC 0.826 || (Accuracy, Precision) 0:( 0.814, 0.942)  1:( 0.839, 0.583) -> AdaBoost\n",
      "Accuracy: 0.849 || AUROC 0.789 || (Accuracy, Precision) 0:( 0.903, 0.900)  1:( 0.674, 0.683) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.751 || AUROC 0.756 || (Accuracy, Precision) 0:( 0.747, 0.911)  1:( 0.765, 0.483) -> Logistic regression\n",
      "Accuracy: 0.719 || AUROC 0.723 || (Accuracy, Precision) 0:( 0.715, 0.896)  1:( 0.730, 0.442) -> SGDClassifier\n",
      "Accuracy: 0.803 || AUROC 0.803 || (Accuracy, Precision) 0:( 0.803, 0.930)  1:( 0.804, 0.557) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.230 || AUROC 0.486 || (Accuracy, Precision) 0:( 0.000, 0.018)  1:( 0.972, 0.231) -> SVM-rbf\n",
      "Accuracy: 0.829 || AUROC 0.716 || (Accuracy, Precision) 0:( 0.930, 0.858)  1:( 0.503, 0.688) -> Gaussian naive bayes\n",
      "Accuracy: 0.807 || AUROC 0.752 || (Accuracy, Precision) 0:( 0.856, 0.887)  1:( 0.648, 0.583) -> Decision Tree\n",
      "Accuracy: 0.789 || AUROC 0.805 || (Accuracy, Precision) 0:( 0.775, 0.939)  1:( 0.836, 0.534) -> Multi-layer Perceptron\n",
      "Accuracy: 0.832 || AUROC 0.825 || (Accuracy, Precision) 0:( 0.838, 0.935)  1:( 0.813, 0.608) -> AdaBoost\n",
      "Accuracy: 0.848 || AUROC 0.789 || (Accuracy, Precision) 0:( 0.900, 0.900)  1:( 0.678, 0.678) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(smoteSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.755 || AUROC 0.756 || (Accuracy, Precision) 0:( 0.754, 0.910)  1:( 0.759, 0.488) -> Logistic regression\n",
      "Accuracy: 0.664 || AUROC 0.702 || (Accuracy, Precision) 0:( 0.630, 0.900)  1:( 0.774, 0.392) -> SGDClassifier\n",
      "Accuracy: 0.799 || AUROC 0.814 || (Accuracy, Precision) 0:( 0.786, 0.942)  1:( 0.842, 0.549) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.801 || AUROC 0.626 || (Accuracy, Precision) 0:( 0.957, 0.814)  1:( 0.295, 0.681) -> SVM-rbf\n",
      "Accuracy: 0.829 || AUROC 0.707 || (Accuracy, Precision) 0:( 0.939, 0.853)  1:( 0.475, 0.707) -> Gaussian naive bayes\n",
      "Accuracy: 0.776 || AUROC 0.772 || (Accuracy, Precision) 0:( 0.779, 0.915)  1:( 0.765, 0.517) -> Decision Tree\n",
      "Accuracy: 0.791 || AUROC 0.793 || (Accuracy, Precision) 0:( 0.790, 0.926)  1:( 0.797, 0.540) -> Multi-layer Perceptron\n",
      "Accuracy: 0.817 || AUROC 0.829 || (Accuracy, Precision) 0:( 0.806, 0.946)  1:( 0.853, 0.576) -> AdaBoost\n",
      "Accuracy: 0.814 || AUROC 0.821 || (Accuracy, Precision) 0:( 0.809, 0.940)  1:( 0.833, 0.574) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(underSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.741 || AUROC 0.754 || (Accuracy, Precision) 0:( 0.728, 0.915)  1:( 0.781, 0.470) -> Logistic regression\n",
      "Accuracy: 0.712 || AUROC 0.715 || (Accuracy, Precision) 0:( 0.710, 0.891)  1:( 0.720, 0.434) -> SGDClassifier\n",
      "Accuracy: 0.770 || AUROC 0.805 || (Accuracy, Precision) 0:( 0.738, 0.949)  1:( 0.872, 0.507) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.803 || AUROC 0.618 || (Accuracy, Precision) 0:( 0.968, 0.811)  1:( 0.269, 0.720) -> SVM-rbf\n",
      "Accuracy: 0.776 || AUROC 0.760 || (Accuracy, Precision) 0:( 0.791, 0.904)  1:( 0.729, 0.519) -> Gaussian naive bayes\n",
      "Accuracy: 0.736 || AUROC 0.732 || (Accuracy, Precision) 0:( 0.740, 0.897)  1:( 0.724, 0.463) -> Decision Tree\n",
      "Accuracy: 0.772 || AUROC 0.781 || (Accuracy, Precision) 0:( 0.764, 0.924)  1:( 0.797, 0.511) -> Multi-layer Perceptron\n",
      "Accuracy: 0.837 || AUROC 0.798 || (Accuracy, Precision) 0:( 0.871, 0.911)  1:( 0.725, 0.635) -> AdaBoost\n",
      "Accuracy: 0.785 || AUROC 0.813 || (Accuracy, Precision) 0:( 0.760, 0.948)  1:( 0.866, 0.527) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(centroidSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.736 || AUROC 0.757 || (Accuracy, Precision) 0:( 0.718, 0.919)  1:( 0.796, 0.466) -> Logistic regression\n",
      "Accuracy: 0.689 || AUROC 0.716 || (Accuracy, Precision) 0:( 0.664, 0.903)  1:( 0.769, 0.414) -> SGDClassifier\n",
      "Accuracy: 0.788 || AUROC 0.816 || (Accuracy, Precision) 0:( 0.764, 0.949)  1:( 0.868, 0.532) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.236 || AUROC 0.500 || (Accuracy, Precision) 0:( 0.000, 1.000)  1:( 1.000, 0.236) -> SVM-rbf\n",
      "Accuracy: 0.814 || AUROC 0.758 || (Accuracy, Precision) 0:( 0.864, 0.889)  1:( 0.653, 0.598) -> Gaussian naive bayes\n",
      "Accuracy: 0.812 || AUROC 0.801 || (Accuracy, Precision) 0:( 0.822, 0.923)  1:( 0.780, 0.575) -> Decision Tree\n",
      "Accuracy: 0.775 || AUROC 0.805 || (Accuracy, Precision) 0:( 0.748, 0.946)  1:( 0.862, 0.514) -> Multi-layer Perceptron\n",
      "Accuracy: 0.803 || AUROC 0.824 || (Accuracy, Precision) 0:( 0.784, 0.949)  1:( 0.864, 0.553) -> AdaBoost\n",
      "Accuracy: 0.828 || AUROC 0.824 || (Accuracy, Precision) 0:( 0.831, 0.936)  1:( 0.816, 0.599) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(smoteeenSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748 || AUROC 0.755 || (Accuracy, Precision) 0:( 0.742, 0.912)  1:( 0.768, 0.479) -> Logistic regression\n",
      "Accuracy: 0.706 || AUROC 0.711 || (Accuracy, Precision) 0:( 0.702, 0.890)  1:( 0.721, 0.428) -> SGDClassifier\n",
      "Accuracy: 0.843 || AUROC 0.785 || (Accuracy, Precision) 0:( 0.894, 0.899)  1:( 0.676, 0.665) -> KNearest Neighbors (5)\n",
      "Accuracy: 0.224 || AUROC 0.473 || (Accuracy, Precision) 0:( 0.000, 0.005)  1:( 0.946, 0.226) -> SVM-rbf\n",
      "Accuracy: 0.822 || AUROC 0.661 || (Accuracy, Precision) 0:( 0.966, 0.829)  1:( 0.357, 0.762) -> Gaussian naive bayes\n",
      "Accuracy: 0.812 || AUROC 0.754 || (Accuracy, Precision) 0:( 0.864, 0.887)  1:( 0.643, 0.594) -> Decision Tree\n",
      "Accuracy: 0.833 || AUROC 0.736 || (Accuracy, Precision) 0:( 0.920, 0.869)  1:( 0.551, 0.682) -> Multi-layer Perceptron\n",
      "Accuracy: 0.857 || AUROC 0.787 || (Accuracy, Precision) 0:( 0.920, 0.896)  1:( 0.653, 0.717) -> AdaBoost\n",
      "Accuracy: 0.852 || AUROC 0.781 || (Accuracy, Precision) 0:( 0.915, 0.893)  1:( 0.647, 0.701) -> Random Forest\n"
     ]
    }
   ],
   "source": [
    "evaluateBalancerAgaintTestData(tomekSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
